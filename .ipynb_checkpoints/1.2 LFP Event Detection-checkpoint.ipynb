{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import public packages and functions\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# inserting the lib folder to the compiler\n",
    "sys.path.insert(0, './lib')\n",
    "sys.path.insert(0, './utils/')\n",
    "\n",
    "#import utils_plotting\n",
    "import utils_accelerometer, utils_misc\n",
    "\n",
    "from lib_LFP import LFP\n",
    "from lib_event import EVENTS\n",
    "from lib_data import DATA_IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CURR   = os.path.abspath(os.curdir)    # current code\n",
    "PATH        = (str(Path(PATH_CURR).parent)) # data repository: upper directory where datasets situated\n",
    "PATH_DATA   = PATH + \"\\\\data\"               # the recordings data directory\n",
    "PATH_EVENTS = PATH + \"\\\\events\"\n",
    "SUB_LIST    = utils_misc.get_SUB_list(PATH_DATA) # get the SUB id list which we have a recording of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_LIST = [\"019\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFP Recording: SUB-019\n"
     ]
    }
   ],
   "source": [
    "for SUB in SUB_LIST:\n",
    "    \n",
    "    LFP_SUB           = LFP(PATH, SUB)\n",
    "    \n",
    "    # 1. Load event history of patient\n",
    "    df_lfp_events     = pd.read_csv(DATA_IO.path_events_dataframe + \"SUB_\"+ SUB +\"_EVENTS_LFP.csv\")\n",
    "    df_lfp_events     = df_lfp_events[df_lfp_events.duration>=0.2]\n",
    "    \n",
    "    # 2. Get the LFP recordings dataframe\n",
    "    df_lfp_recordings = LFP_SUB.extract_LFP_events_segments(df_lfp_events)\n",
    "    \n",
    "    # 3. Save the dataframe as a pickle file\n",
    "    df_lfp_recordings.to_pickle(DATA_IO.path_events_dataframe + \"SUB_\"+ SUB +\"_EVENTS_LFP_RECORDINGS.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
