{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aedc170-51a9-41dd-ab2c-d9959e489a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a.kaymak\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\a.kaymak\\Anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pyvista as pv \n",
    "import pyvista\n",
    "from pyvista import demos\n",
    "from pyvista import examples \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# inserting the lib folder to the compiler\n",
    "sys.path.insert(0, './lib')\n",
    "sys.path.insert(0, './utils/')\n",
    "\n",
    "import utils_misc\n",
    "\n",
    "from lib_data import DATA_IO\n",
    "import lib_Subcortical_Atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc44c92e-8abd-44bd-a1cf-c0e92cd1a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CURR           = os.path.abspath(os.curdir)    # current code\n",
    "PATH                = (str(Path(PATH_CURR).parent)) # data repository: upper directory where datasets situated\n",
    "SUB_LIST            = utils_misc.get_SUB_list(DATA_IO.path_data) # get the SUB id list which we have a recording of them\n",
    "\n",
    "\n",
    "basal_ganglia       = lib_Subcortical_Atlases.Distal_Atlas(threshold=0.5)\n",
    "contact_coordinates = pd.read_csv(DATA_IO.path_coordinates + \"contact_coordinates.csv\")\n",
    "event_files         = utils_misc.get_files_with_specific_format(DATA_IO.path_events, suffix=\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53b0ef-f116-40be-bbe6-f1316c914f44",
   "metadata": {},
   "source": [
    "# 1. CREATE THE CHANNEL PARCELLATION & MAP DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad6f1b-9ce2-4b72-ab40-0de3e3775028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... SUB-008\n",
      "... SUB-009\n"
     ]
    }
   ],
   "source": [
    "df_channel_stn_position = pd.DataFrame(columns=[\"patient\", \"hemisphere\", \"channel\", \"x\", \"y\", \"z\", \n",
    "                                                \"contact1_area\", \"contact2_area\", \"channel_area\"])\n",
    "\n",
    "for file in event_files:\n",
    "    if(\"LFP\" in file):\n",
    "        \n",
    "        SUB           = file[4:7]\n",
    "        df_lfp_events = pd.read_pickle(DATA_IO.path_events + file)\n",
    "        LFP_channels  = df_lfp_events.LFP_channel.unique()\n",
    "\n",
    "        print(\"... SUB-\" + SUB)\n",
    "        \n",
    "        for HEMISPHERE in [\"right\", \"left\"]:\n",
    "            for CHANNEL in LFP_channels:\n",
    "                # get the contact names\n",
    "                CONTACT1 = int(CHANNEL.split(\"-\")[0])\n",
    "                CONTACT2 = int(CHANNEL.split(\"-\")[1])\n",
    "\n",
    "                # get the contact coordinates\n",
    "                contact_1_coor = contact_coordinates[(contact_coordinates.patient == int(SUB)) & \n",
    "                                                     (contact_coordinates.hemisphere == HEMISPHERE) & \n",
    "                                                     (contact_coordinates.recording_type == \"lfp\") &  \n",
    "                                                     (contact_coordinates.contact == CONTACT1)]\n",
    "                contact_2_coor = contact_coordinates[(contact_coordinates.patient == int(SUB)) & \n",
    "                                                     (contact_coordinates.hemisphere == HEMISPHERE) & \n",
    "                                                     (contact_coordinates.recording_type == \"lfp\") &  \n",
    "                                                     (contact_coordinates.contact == CONTACT2)]\n",
    "                row               = {}\n",
    "                row[\"patient\"]    = SUB\n",
    "                row[\"hemisphere\"] = HEMISPHERE\n",
    "                row[\"channel\"]    = CHANNEL\n",
    "    \n",
    "                if((len(contact_1_coor) != 0) & (len(contact_2_coor) != 0)):\n",
    "\n",
    "                    # get the coordinates of the contacts\n",
    "                    try:\n",
    "                        row[\"contact1_area\"]  = basal_ganglia.check_position_in_nucleus(basal_ganglia.STN, HEMISPHERE,\n",
    "                                                                                        [[float(contact_1_coor.x), float(contact_1_coor.y), float(contact_1_coor.z)]])\n",
    "                        row[\"contact2_area\"]  = basal_ganglia.check_position_in_nucleus(basal_ganglia.STN, HEMISPHERE,\n",
    "                                                                                        [[float(contact_2_coor.x), float(contact_2_coor.y), float(contact_2_coor.z)]])\n",
    "                    except:\n",
    "                        print(contact_1_coor)\n",
    "                        print(contact_2_coor)\n",
    "                    row[\"x\"]              = (float(contact_1_coor.x) + float(contact_2_coor.x)) / 2\n",
    "                    row[\"y\"]              = (float(contact_1_coor.y) + float(contact_2_coor.y)) / 2\n",
    "                    row[\"z\"]              = (float(contact_1_coor.z) + float(contact_2_coor.z)) / 2\n",
    "\n",
    "                    # check the position of channels (correspond to functional area within STN)\n",
    "                    row[\"channel_area\"]   = basal_ganglia.check_position_in_nucleus(basal_ganglia.STN, HEMISPHERE,\n",
    "                                                                                   [[row[\"x\"], row[\"y\"], row[\"z\"]]])         \n",
    "\n",
    "                    # In same case, one of the two contacts resides outside of  STN meanwhile the other one situated within the STN.\n",
    "                    # For this particular case, if also estimated position of the channel resides outside of the STN, we assign channel area same \n",
    "                    # with the contact that situated in STN.\n",
    " \n",
    "                    if(((row[\"contact1_area\"])==\"outside\") & ((row[\"contact2_area\"])!=\"outside\") & ((row[\"channel_area\"])==\"outside\")):\n",
    "                        row[\"channel_area\"] = row[\"contact2_area\"]\n",
    "                        \n",
    "                    elif(((row[\"contact1_area\"])!=\"outside\") & ((row[\"contact2_area\"])==\"outside\") & ((row[\"channel_area\"])==\"outside\")):\n",
    "                        row[\"channel_area\"] = row[\"contact1_area\"]\n",
    "                        \n",
    "                    df_channel_stn_position.loc[len(df_channel_stn_position)] = row \n",
    "\n",
    "df_channel_stn_position.to_pickle(DATA_IO.path_coordinates + \"lfp_channel_stn_parcellation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e970982-58e8-4fc8-a096-7328513dbfca",
   "metadata": {},
   "source": [
    "# 2. DIVIDE LFP EVENTS ACROSS PATIENTS BASED ON CHANNEL STN LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a2786-f85f-495f-8fa8-eaddbf69ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel_stn_position   = pd.read_pickle(DATA_IO.path_coordinates + \"lfp_channel_stn_parcellation.pkl\")\n",
    "\n",
    "# create empty dataframe with same column structure of event dataframes\n",
    "\n",
    "# tapping\n",
    "df_lfp_tapping_events_motor_area        = pd.DataFrame(columns = ['patient', 'event_no', 'event_category', 'event_laterality',\n",
    "                                                                  'event_start_time', 'duration', 'LFP_hemisphere', 'LFP_channel',\n",
    "                                                                  'pre_event_recording', 'event_recording', 'post_event_recording',\n",
    "                                                                  'CDRS_right_hand', 'CDRS_left_hand', 'CDRS_total', 'dyskinesia_arm','dyskinesia_total'])\n",
    "\n",
    "\n",
    "df_lfp_tapping_events_associative_area  = pd.DataFrame(columns=df_lfp_tapping_events_motor_area.columns)\n",
    "df_lfp_tapping_events_limbic_area       = pd.DataFrame(columns=df_lfp_tapping_events_motor_area.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e75ea-c221-43e0-aadb-e46d41766cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in event_files:\n",
    "    \n",
    "    if(\"LFP\" in file):\n",
    "        \n",
    "        df_lfp_events = pd.read_pickle(DATA_IO.path_events + file)\n",
    "        SUB           = df_lfp_events.iloc[0].patient\n",
    "        print(\"... SUB-\" + SUB)\n",
    "\n",
    "        for index, event_row in df_lfp_events.iterrows():\n",
    "    \n",
    "            event_category = event_row.event_category\n",
    "            hemisphere     = event_row.LFP_hemisphere\n",
    "            channel        = event_row.LFP_channel\n",
    "        \n",
    "            stn_area_row   = df_channel_stn_position[(df_channel_stn_position.patient == SUB) & \n",
    "                                                     (df_channel_stn_position.hemisphere == hemisphere) &\n",
    "                                                     (df_channel_stn_position.channel == channel)]\n",
    "            \n",
    "            if(len(stn_area_row)!=0): # if the location of the specified channel is known\n",
    "                \n",
    "                stn_area =  stn_area_row.iloc[0,8]\n",
    "                \n",
    "                if(stn_area==\"motor\"):\n",
    "                    df_lfp_tapping_events_motor_area.loc[len(df_lfp_tapping_events_motor_area)] = event_row\n",
    "                elif(stn_area==\"associative\"):\n",
    "                    df_lfp_tapping_events_associative_area.loc[len(df_lfp_tapping_events_associative_area)] = event_row\n",
    "                elif(stn_area==\"limbic\"):\n",
    "                    df_lfp_tapping_events_limbic_area.loc[len(df_lfp_tapping_events_limbic_area)] = event_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e78121-a040-4f82-b5dc-cd72be60e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lfp_tapping_events_motor_area.to_pickle(DATA_IO.path_events + \"LFP_TAPPING_EVENTS_MOTOR_AREA.pkl\")\n",
    "df_lfp_tapping_events_associative_area.to_pickle(DATA_IO.path_events + \"LFP_TAPPING_EVENTS_ASSOCIATIVE_AREA.pkl\")\n",
    "df_lfp_tapping_events_limbic_area.to_pickle(DATA_IO.path_events + \"LFP_TAPPING_EVENTS_LIMBIC_AREA.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdeeb4b-c116-4bc3-89ac-c61ff40814d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
